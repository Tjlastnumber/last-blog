[
  {
    "objectID": "Welcome.html",
    "href": "Welcome.html",
    "title": "Lastnumber",
    "section": "",
    "text": "This is your new vault.\nMake a note of something, [[create a link]], or try the Importer!\nWhen you’re ready, delete this note and make the vault your own."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "First Blog"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html",
    "href": "posts/prometheus/dockerswarm.html",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "想要使用 prometheus 监控 docker swarm 的集群以及集群中的容器，按照 prometheus 官方的文档实现的话，需要将所有容器的端口都暴露出来，出于安全和维护得考虑我并不想把所有的容器端口都暴露到容器集群之外，而是只使用一个代理服务暴露出来。通过服务名称在集群内通信。关于这部分网络通信可以查看 docker swarm 网络相关文档。这里引用一段关于 overlay 网络的说明。\n\noverlay: Overlay networks connect multiple Docker daemons together and enable Swarm services and containers to communicate across nodes. This strategy removes the need to do OS-level routing. See Overlay network driver.\n\noverlay: 覆盖网络将多个 Docker 守护进程连接在一起，并使 Swarm 服务和容器能够跨节点通信。此策略消除了进行操作系统级路由的需要。\n\n\n由于网络的限制，prometheus 不能从外部访问 docker swarm 的 overlay 网络，prometheus 无法在外部访问应用端口，所以需要将 prometheus 部署对应的 stack 环境并加入到 ingress 网络，这样就能在内部通过 vip 或者 service name 访问容器。\nprometheus 官方并没有提供关于这个的最佳解决方案，所以才有了本篇文章。\n\n\n\n以下是我在官方关于 docker swarm 服务发现的配置基础上做了部分改进。建议先查看 prometheus 官方文档再看以下部分，可以帮助理解。\n\n修改 /etc/docker/daemon.json 添加配置：\n\n{\n  \"metrics-addr\": \"0.0.0.0:9323\",\n  \"experimental\": true\n}\n也可以配置 ip 地址而不是 0.0.0.0\n\n重启 docker 守护进程\n\n$ systemctl restart docker\n\n\n\n\n\n\n注意\n\n\n\n\n需要集群中所有 docker 节点打开 9323 端口\n需要打开服务器防火墙\n\n\n\n\n\n\n我们需要将 prometheus 的配置挂载到容器外的宿主机上，这里有两种方式可以使用：\n\n只读方式挂载到宿主机本地磁盘\n使用 docker config 方式配置到容器的配置列表。\n\n这里采用里的 2 的方式，这样便于从容器相关可视化页面查看，例如： portainer\n在 docker swarm manager节点 创建 prometheus.yml 文件:\n# my global config\nglobal:\n  scrape_interval: 1m # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 1m # Evaluate rules every 15 seconds. The default is every 1 minute.\n  scrape_timeout: 10s # scrape_timeout is set to the global default (10s).\n\n# Alertmanager configuration\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          # - alertmanager:9093\n          \nscrape_configs:\n1  - job_name: \"dockerswarm\"\n2    dockerswarm_sd_configs:\n      - host: unix:///var/run/docker.sock\n        role: nodes\n    relabel_configs:\n3      - source_labels: [__meta_dockerswarm_node_address]\n        target_label: __address__\n        replacement: $1:9323\n4      - source_labels: [__meta_dockerswarm_node_hostname]\n        target_label: instance\n\n5  - job_name: 'dockertasks'\n    metrics_path: /actuator/prometheus\n    dockerswarm_sd_configs:\n      - host: unix:///var/run/docker.sock\n        role: tasks\n    relabel_configs:\n      # Only keep containers that should be running.\n6      - source_labels: [__meta_dockerswarm_task_desired_state]\n        regex: running\n        action: keep\n7      - source_labels: [__meta_dockerswarm_container_label_com_docker_stack_namespace]\n        regex: dev\n        action: keep\n8      - source_labels: [__meta_dockerswarm_container_label_external_metrics_enable]\n        regex: true\n        action: keep\n9      - source_labels: [__address__]\n        target_label: __address__\n        regex: '(.+):.*'\n        replacement: $1:8080\n10      - source_labels: [__meta_dockerswarm_service_label_com_docker_stack_namespace]\n        target_label: namespace\n11      - source_labels: [__meta_dockerswarm_service_name]\n        target_label: serviceName\n12      - source_labels: [__meta_dockerswarm_service_name]\n        target_label: application\n13      - source_labels: [__meta_dockerswarm_task_id]\n        target_label: instance\n\n1\n\njob_name:\"dockerswarm\": docker swarm 节点监控\n\n2\n\ndockerswarm_sd_configs: 使用 prometheus 内置支持的 dockerswarm 服务发现配置 ;host: 配置 unix:///var/run/docker.sock 访问 docker 的守护进程 ;role: 配置为 node 用于访问表示监控 docker swarm 节点\n\n3\n\n__meta_dockerswarm_node_address: 使用 docker swarm 节点地址替换 __address label\n\n4\n\n__meta_dockerswarm_node_hostname: 使用 docker swarm hostname 替换 instance label\n\n5\n\njob_name: 'dockertasks': docker task 监控, 监控容器\n\n6\n\ndockerswarm_sd_configs: 同样使用 docker swarm 服务发现配置 ;host: 配置 unix:///var/run/docker.sock 访问 docker 的守护进程 ;role: 配置为 tasks 用于访问表示监控 docker swarm 运行的容器\n\n7\n\n__meta_dockerswarm_task_desired_state: 过滤容器运行状态要保持容器状态微 running\n\n8\n\n__meta_dockerswarm_container_label_com_docker_stack_namespace: 容器运行的命名空间, 对应的是 docker swarm 中的 stock , namespace 是 k8s 中不同环境之间隔离的划分名称, 这里过滤掉 stock 非 dev\n\n9\n\n__meta_dockerswarm_container_label_external_metrics_enable: 过滤开启了监控的容器\n\n10\n\n__address__: 替换默认监控容器的端口, 我习惯上使用容器内的 8080 端口作为服务的默认访问端口, 可以根据跟人习惯修改\n\n11\n\n__meta_dockerswarm_service_label_com_docker_stack_namespace: 使用 stack 替换 namespace\n\n12\n\n__meta_dockerswarm_service_name: 使用docker swarm的服务名称替换掉 application 和 serviceName label\n\n13\n\n__meta_dockerswarm_task_id: 使用 task_id 替换掉 instance\n\n\n\n\n\n创建 docker_compose.yml 文件:\n$ vim docker_compose.yml\n写入以下配置:\nversion: \"3.5\"\n\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n1    user: root\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n2          - node.role == manager\n    networks:\n      - overlay\n    configs:\n3      - source: prometheus_config\n        target: /etc/prometheus/prometheus.yml\n    command:\n4      - '--config.file=/etc/prometheus/prometheus.yml'\n    volumes:\n5      - /var/run/docker.sock:/var/run/docker.sock:ro\n\nconfigs:\n  prometheus_config:\n6    file: ./prometheus.yml\n\nnetworks:\n  overlay:\n\n1\n\nuser：root: 使用 root 用户创建容器，因为需要监听 docker.sock\n\n2\n\nnode.role == manager: 设置角色为 manager, 因为需要将 prometheus 容器运行在 docker swarm 的主节点上\n\n3\n\nprometheus_config: 是上一步设置的 docker config 名称\n\n4\n\nconfig.file=/etc/prometheus/prometheus.yml: 设置 prometheus 启动时使用的命令\n\n5\n\n/var/run/docker.sock:/var/run/docker.sock:ro: 挂载 docker 的守护进程\n\n6\n\nconfigs: 对应 &lt;3&gt; 的配置设置, 指定使用当前启动 docker_compose.yml 文件的相对路径下的 prometheus.yml\n\n\n\n\n\n在目标 stack 环境部署 prometheus\n$ docker stack deploy -c docker_compose.yml {stack}\n\n\n\n\n\n\n注意\n\n\n\n如果是多套 stock 环境则必须每个 stock 中都要部署 prometheus 用于监控, 这是因为 docker swarm 默认的 overlay 网络之间不能互相通信. 同时每个容器只能配置唯一的 overlay 网络"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html#背景",
    "href": "posts/prometheus/dockerswarm.html#背景",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "想要使用 prometheus 监控 docker swarm 的集群以及集群中的容器，按照 prometheus 官方的文档实现的话，需要将所有容器的端口都暴露出来，出于安全和维护得考虑我并不想把所有的容器端口都暴露到容器集群之外，而是只使用一个代理服务暴露出来。通过服务名称在集群内通信。关于这部分网络通信可以查看 docker swarm 网络相关文档。这里引用一段关于 overlay 网络的说明。\n\noverlay: Overlay networks connect multiple Docker daemons together and enable Swarm services and containers to communicate across nodes. This strategy removes the need to do OS-level routing. See Overlay network driver.\n\noverlay: 覆盖网络将多个 Docker 守护进程连接在一起，并使 Swarm 服务和容器能够跨节点通信。此策略消除了进行操作系统级路由的需要。\n\n\n由于网络的限制，prometheus 不能从外部访问 docker swarm 的 overlay 网络，prometheus 无法在外部访问应用端口，所以需要将 prometheus 部署对应的 stack 环境并加入到 ingress 网络，这样就能在内部通过 vip 或者 service name 访问容器。\nprometheus 官方并没有提供关于这个的最佳解决方案，所以才有了本篇文章。"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html#打开-docker-采集端口",
    "href": "posts/prometheus/dockerswarm.html#打开-docker-采集端口",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "以下是我在官方关于 docker swarm 服务发现的配置基础上做了部分改进。建议先查看 prometheus 官方文档再看以下部分，可以帮助理解。\n\n修改 /etc/docker/daemon.json 添加配置：\n\n{\n  \"metrics-addr\": \"0.0.0.0:9323\",\n  \"experimental\": true\n}\n也可以配置 ip 地址而不是 0.0.0.0\n\n重启 docker 守护进程\n\n$ systemctl restart docker\n\n\n\n\n\n\n注意\n\n\n\n\n需要集群中所有 docker 节点打开 9323 端口\n需要打开服务器防火墙"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html#在-docker-swarm-创建-configs",
    "href": "posts/prometheus/dockerswarm.html#在-docker-swarm-创建-configs",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "我们需要将 prometheus 的配置挂载到容器外的宿主机上，这里有两种方式可以使用：\n\n只读方式挂载到宿主机本地磁盘\n使用 docker config 方式配置到容器的配置列表。\n\n这里采用里的 2 的方式，这样便于从容器相关可视化页面查看，例如： portainer\n在 docker swarm manager节点 创建 prometheus.yml 文件:\n# my global config\nglobal:\n  scrape_interval: 1m # Set the scrape interval to every 15 seconds. Default is every 1 minute.\n  evaluation_interval: 1m # Evaluate rules every 15 seconds. The default is every 1 minute.\n  scrape_timeout: 10s # scrape_timeout is set to the global default (10s).\n\n# Alertmanager configuration\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          # - alertmanager:9093\n          \nscrape_configs:\n1  - job_name: \"dockerswarm\"\n2    dockerswarm_sd_configs:\n      - host: unix:///var/run/docker.sock\n        role: nodes\n    relabel_configs:\n3      - source_labels: [__meta_dockerswarm_node_address]\n        target_label: __address__\n        replacement: $1:9323\n4      - source_labels: [__meta_dockerswarm_node_hostname]\n        target_label: instance\n\n5  - job_name: 'dockertasks'\n    metrics_path: /actuator/prometheus\n    dockerswarm_sd_configs:\n      - host: unix:///var/run/docker.sock\n        role: tasks\n    relabel_configs:\n      # Only keep containers that should be running.\n6      - source_labels: [__meta_dockerswarm_task_desired_state]\n        regex: running\n        action: keep\n7      - source_labels: [__meta_dockerswarm_container_label_com_docker_stack_namespace]\n        regex: dev\n        action: keep\n8      - source_labels: [__meta_dockerswarm_container_label_external_metrics_enable]\n        regex: true\n        action: keep\n9      - source_labels: [__address__]\n        target_label: __address__\n        regex: '(.+):.*'\n        replacement: $1:8080\n10      - source_labels: [__meta_dockerswarm_service_label_com_docker_stack_namespace]\n        target_label: namespace\n11      - source_labels: [__meta_dockerswarm_service_name]\n        target_label: serviceName\n12      - source_labels: [__meta_dockerswarm_service_name]\n        target_label: application\n13      - source_labels: [__meta_dockerswarm_task_id]\n        target_label: instance\n\n1\n\njob_name:\"dockerswarm\": docker swarm 节点监控\n\n2\n\ndockerswarm_sd_configs: 使用 prometheus 内置支持的 dockerswarm 服务发现配置 ;host: 配置 unix:///var/run/docker.sock 访问 docker 的守护进程 ;role: 配置为 node 用于访问表示监控 docker swarm 节点\n\n3\n\n__meta_dockerswarm_node_address: 使用 docker swarm 节点地址替换 __address label\n\n4\n\n__meta_dockerswarm_node_hostname: 使用 docker swarm hostname 替换 instance label\n\n5\n\njob_name: 'dockertasks': docker task 监控, 监控容器\n\n6\n\ndockerswarm_sd_configs: 同样使用 docker swarm 服务发现配置 ;host: 配置 unix:///var/run/docker.sock 访问 docker 的守护进程 ;role: 配置为 tasks 用于访问表示监控 docker swarm 运行的容器\n\n7\n\n__meta_dockerswarm_task_desired_state: 过滤容器运行状态要保持容器状态微 running\n\n8\n\n__meta_dockerswarm_container_label_com_docker_stack_namespace: 容器运行的命名空间, 对应的是 docker swarm 中的 stock , namespace 是 k8s 中不同环境之间隔离的划分名称, 这里过滤掉 stock 非 dev\n\n9\n\n__meta_dockerswarm_container_label_external_metrics_enable: 过滤开启了监控的容器\n\n10\n\n__address__: 替换默认监控容器的端口, 我习惯上使用容器内的 8080 端口作为服务的默认访问端口, 可以根据跟人习惯修改\n\n11\n\n__meta_dockerswarm_service_label_com_docker_stack_namespace: 使用 stack 替换 namespace\n\n12\n\n__meta_dockerswarm_service_name: 使用docker swarm的服务名称替换掉 application 和 serviceName label\n\n13\n\n__meta_dockerswarm_task_id: 使用 task_id 替换掉 instance"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html#docker_compose.yml-配置",
    "href": "posts/prometheus/dockerswarm.html#docker_compose.yml-配置",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "创建 docker_compose.yml 文件:\n$ vim docker_compose.yml\n写入以下配置:\nversion: \"3.5\"\n\nservices:\n  prometheus:\n    image: prom/prometheus:latest\n    ports:\n      - \"9090:9090\"\n1    user: root\n    deploy:\n      mode: replicated\n      replicas: 1\n      placement:\n        constraints:\n2          - node.role == manager\n    networks:\n      - overlay\n    configs:\n3      - source: prometheus_config\n        target: /etc/prometheus/prometheus.yml\n    command:\n4      - '--config.file=/etc/prometheus/prometheus.yml'\n    volumes:\n5      - /var/run/docker.sock:/var/run/docker.sock:ro\n\nconfigs:\n  prometheus_config:\n6    file: ./prometheus.yml\n\nnetworks:\n  overlay:\n\n1\n\nuser：root: 使用 root 用户创建容器，因为需要监听 docker.sock\n\n2\n\nnode.role == manager: 设置角色为 manager, 因为需要将 prometheus 容器运行在 docker swarm 的主节点上\n\n3\n\nprometheus_config: 是上一步设置的 docker config 名称\n\n4\n\nconfig.file=/etc/prometheus/prometheus.yml: 设置 prometheus 启动时使用的命令\n\n5\n\n/var/run/docker.sock:/var/run/docker.sock:ro: 挂载 docker 的守护进程\n\n6\n\nconfigs: 对应 &lt;3&gt; 的配置设置, 指定使用当前启动 docker_compose.yml 文件的相对路径下的 prometheus.yml"
  },
  {
    "objectID": "posts/prometheus/dockerswarm.html#在-docker-swarm-集群部署",
    "href": "posts/prometheus/dockerswarm.html#在-docker-swarm-集群部署",
    "title": "docker swarm 部署 prometheus 监控",
    "section": "",
    "text": "在目标 stack 环境部署 prometheus\n$ docker stack deploy -c docker_compose.yml {stack}\n\n\n\n\n\n\n注意\n\n\n\n如果是多套 stock 环境则必须每个 stock 中都要部署 prometheus 用于监控, 这是因为 docker swarm 默认的 overlay 网络之间不能互相通信. 同时每个容器只能配置唯一的 overlay 网络"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Blog",
    "section": "",
    "text": "docker swarm 部署 prometheus 监控\n\n\n\n\n\n\nnews\n\n\nprometheus\n\n\ndocker swarm\n\n\n\n使用 prometheus 同时监控 docker swarm 集群的多个 stock\n\n\n\n\n\nApr 8, 2024\n\n\nlastnumber\n\n\n\n\n\n\n\n\n\n\n\n\n使用 Obsidian 编写 Quarto 博客\n\n\n\n\n\n\nobsidian\n\n\nquarto\n\n\n\n\n\n\n\n\n\nApr 8, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n监控的选型\n\n\n\n\n\n\nnews\n\n\nmonitoring\n\n\nprometheus\n\n\n\n\n\n\n\n\n\nApr 3, 2024\n\n\nlastnumber\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\nnew begin\n\n\n\n\n\n\n\n\n\nApr 14, 1990\n\n\nLastnumber\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/prometheus/index.html",
    "href": "posts/prometheus/index.html",
    "title": "监控的选型",
    "section": "",
    "text": "Prometheus 监控"
  },
  {
    "objectID": "posts/Obsidian/index.html",
    "href": "posts/Obsidian/index.html",
    "title": "使用 Obsidian 编写 Quarto 博客",
    "section": "",
    "text": "Obsidian是一款基于 Markdown 的笔记编辑器，具有双向链接、图形化关系展示、标签和目录管理等功能。它支持插件扩展，提供本地存储和加密，跨平台支持，并适用于个人知识管理、学习和项目管理。\n之前我用过印象笔记（Evernote)、Notion、Joplin：\n\n印象笔记：比较老牌的笔记管理工具，但当时对 markdown 文档支持不是那么理想，设计上也是传统的页面，而且不支持插件。他的优势在于对网页的快速保存。所以现在是作为我的网页收藏夹来使用。\nJoplin：是比较现代的化的 markdown 编辑器，优点是支持插件、可以云盘存储比如 OneDriver, 同时支持 vim 编辑方式, 这个是我最初使用他的原因, 对于文档的整理和跳转, 以及 markdown 的渲染不够美观.\nNotion: 这是比较有名的在线笔记工具, 可以使用”块”的方式编辑笔记, 提供了比较新颖的交互方式, 但是他对于我来说有个致命的弱点就是不能完全通过键盘操作, 不支持 vim 模式, 我比较依赖 vim 的编辑方式, 频繁操作鼠标容易让我打断思路. 所以没有重度的使用 notion, 他更多是作为看板工具.\n\nObsidian 非常符合我的使用习惯, 原生支持 vim 模式, 可以使用 github 作为笔记存储仓库, 同时他 vault 的笔记管理模式, 可以支持不同的笔记仓库上传到不同的 git 仓库, 这样可以很好的将工作和生活笔记做区分。 还有丰富的插件提供了很多功能。它就像是一个专门为了笔记而生的 vscode 但是他比 vscode 更美观。\n\n\n\n他是一个\n---\ntitle: 使用 Obsidian 编写 Quarto 博客\ncategories:\n  - obsidian\n  - quarto\ndate: 2024-04-03\nimage: image.png\n---"
  },
  {
    "objectID": "posts/Obsidian/index.html#obsidian-介绍",
    "href": "posts/Obsidian/index.html#obsidian-介绍",
    "title": "使用 Obsidian 编写 Quarto 博客",
    "section": "",
    "text": "Obsidian是一款基于 Markdown 的笔记编辑器，具有双向链接、图形化关系展示、标签和目录管理等功能。它支持插件扩展，提供本地存储和加密，跨平台支持，并适用于个人知识管理、学习和项目管理。\n之前我用过印象笔记（Evernote)、Notion、Joplin：\n\n印象笔记：比较老牌的笔记管理工具，但当时对 markdown 文档支持不是那么理想，设计上也是传统的页面，而且不支持插件。他的优势在于对网页的快速保存。所以现在是作为我的网页收藏夹来使用。\nJoplin：是比较现代的化的 markdown 编辑器，优点是支持插件、可以云盘存储比如 OneDriver, 同时支持 vim 编辑方式, 这个是我最初使用他的原因, 对于文档的整理和跳转, 以及 markdown 的渲染不够美观.\nNotion: 这是比较有名的在线笔记工具, 可以使用”块”的方式编辑笔记, 提供了比较新颖的交互方式, 但是他对于我来说有个致命的弱点就是不能完全通过键盘操作, 不支持 vim 模式, 我比较依赖 vim 的编辑方式, 频繁操作鼠标容易让我打断思路. 所以没有重度的使用 notion, 他更多是作为看板工具.\n\nObsidian 非常符合我的使用习惯, 原生支持 vim 模式, 可以使用 github 作为笔记存储仓库, 同时他 vault 的笔记管理模式, 可以支持不同的笔记仓库上传到不同的 git 仓库, 这样可以很好的将工作和生活笔记做区分。 还有丰富的插件提供了很多功能。它就像是一个专门为了笔记而生的 vscode 但是他比 vscode 更美观。"
  },
  {
    "objectID": "posts/Obsidian/index.html#quarto-介绍",
    "href": "posts/Obsidian/index.html#quarto-介绍",
    "title": "使用 Obsidian 编写 Quarto 博客",
    "section": "",
    "text": "他是一个\n---\ntitle: 使用 Obsidian 编写 Quarto 博客\ncategories:\n  - obsidian\n  - quarto\ndate: 2024-04-03\nimage: image.png\n---"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "My Projects"
  }
]